Compendio Exhaustivo sobre Ingeniería de Software, Ética de la IA y Descubrimiento Inicial del Proyecto
1. Ingeniería de Software Ayer y Hoy (Nube, IA, Producto)
La ingeniería de software (IS) es una disciplina de ingeniería que se ocupa de todos los aspectos de la producción de software. El concepto mismo surgió originalmente en 1968, en una conferencia destinada a discutir la denominada "crisis del software". En sus inicios, los grandes sistemas de software a menudo presentaban retrasos, no cumplían con la funcionalidad requerida por los usuarios, costaban más de lo esperado y carecían de fiabilidad.
El progreso ha sido notable desde entonces, y hoy en día, las sociedades dependen de sistemas de software profesionales para infraestructuras nacionales, servicios públicos, manufactura y finanzas. La IS incluye actividades fundamentales como la especificación, el desarrollo, la validación y la evolución del software.
1.1 El Enfoque en Productos y la Evolución a la Agilidad
Un enfoque moderno de la IS se centra en los productos de software en lugar de solo en los proyectos. Los productos de software pueden ser genéricos (sistemas independientes vendidos en el mercado abierto) o personalizados (desarrollados para un cliente específico).
En el entorno empresarial actual, que cambia rápidamente, la entrega y el desarrollo rápidos son, por lo general, el requerimiento fundamental de los sistemas de software. Esto ha impulsado la adopción de métodos ágiles. Los métodos ágiles, como Scrum y la Programación Extrema (XP), surgieron en la década de 1990 por el descontento con los enfoques engorrosos de la ingeniería de software basada en la planeación.
Un aspecto clave de los enfoques ágiles es el desarrollo incremental, donde las actividades de especificación, desarrollo y validación están entrelazadas en lugar de separadas. Un beneficio del desarrollo incremental es que "Es posible que sea más rápida la entrega e implementación de software útil al cliente, aun si no se ha incluido toda la funcionalidad". La Programación Extrema (XP) adopta un enfoque "extremo" de este desarrollo incremental, ya que las nuevas versiones del software se construyen varias veces al día y se entregan a los clientes cada dos semanas aproximadamente.
1.2 La Era del Cloud y la Arquitectura Nativa
La computación en nube (Cloud computing) se ha consolidado como la forma habitual y estándar en que las empresas tecnológicas acceden a infraestructuras de TI. El concepto se materializó con la visión de catalogar la computación como una utilidad pública. La nube se implementa utilizando una "nube" de servidores de un proveedor externo y tecnología de virtualización.
Los proveedores de servicios en la nube ofrecen tres modelos principales:
• IaaS (Infraestructura como servicio): El usuario controla el sistema operativo y las aplicaciones; el proveedor gestiona el hardware y el almacenamiento.
• PaaS (Plataforma como servicio): El proveedor ofrece, ejecuta y mantiene el software del sistema y otros recursos, incluyendo el diseño, desarrollo y alojamiento de aplicaciones.
• SaaS (Software como servicio): Las aplicaciones se ofrecen al usuario final, sin que este se preocupe por el mantenimiento del servicio o la gestión de la infraestructura.
La irrupción de la computación cloud ha impulsado la necesidad de arquitecturas cloud native. Según la Cloud Native Computing Foundation (CNCF), la computación cloud native es "el conjunto de tecnologías que descomponen las aplicaciones en microservicios y los empaquetan en contenedores ligeros para desplegarlos y orquestarlos a través de una variedad de servidores". La arquitectura cloud native madura utilizará inteligencia artificial y aprendizaje automático (ML) para monitorear, detectar anomalías y realizar ajustes proactivos para evitar la degradación del rendimiento o la seguridad.
1.3 La Integración de la Inteligencia Artificial (IA)
La Inteligencia Artificial (IA) está revolucionando todo, siendo una de las tecnologías más disruptivas de la Cuarta Revolución Industrial. En la ingeniería de software, la IA se está aplicando para mejorar la productividad y la confiabilidad del desarrollo, así como para automatizar procesos.
La IA generativa, que se centra en la creación de contenido nuevo y original como texto e imágenes, ha tenido un impacto significativo en el desarrollo de software. Herramientas basadas en modelos de lenguaje grande (LLMs), como GitHub Copilot, están facilitando la generación y depuración de código. Se anticipa que "para el año 2028, el 90% de los ingenieros de software empresarial utilizarán asistentes de código basados en IA (14% en 2024)".
La adopción de la IA en el desarrollo de software (AIFSD) tiene implicaciones significativas, llevando a que el rol del desarrollador se desplace de la implementación a la orquestación y el diseño de sistemas. Sin embargo, esta aceleración del proceso también amplifica los errores si no se ejerce una supervisión cuidadosa.
"Si no prestas atención a lo que hace la IA, debido a los volúmenes que puede producir, será una muerte por mil cortes de papel" (Ferri, citado en Thoughtworks).
2. Ética, Privacidad y Uso Responsable de IA
El estudio de la ética en la informática ha ganado una atención significativa en la última década, en particular con la aparición de los nuevos sistemas de inteligencia artificial. La IA no es una herramienta neutral, y sus algoritmos "reflejan valores e intereses de sus diseñadores", con el riesgo de amplificar desigualdades e impactar derechos fundamentales.
2.1 Principios de la IA Responsable
Avanzar hacia una gobernanza ética y responsable de la IA es una exigencia para proteger los derechos fundamentales, la equidad, la transparencia y la confianza pública. La gobernanza ética de la IA se refiere al "conjunto de políticas, procesos, normas y marcos institucionales que garantizan el desarrollo y la aplicación ética, legal y socialmente responsable de las tecnologías de IA".
Principios comunes que definen la gobernanza ética de la IA incluyen: Transparencia, Responsabilidad, No discriminación, Privacidad y protección de datos, Sostenibilidad y Seguridad.
El marco de responsabilidad RAF (Framework for Responsible Generative AI), propuesto por Dataiku, se basa en cuatro pilares fundamentales: fiabilidad, rendición de cuentas, equidad y transparencia. En el contexto de la IA generativa, la importancia de la IA responsable es crucial, ya que los productos desarrollados sin tener en cuenta el sesgo, la robustez y el contexto social pueden llevar a "fallas significativas en su aplicación".
A nivel internacional, organizaciones como la UNESCO y la OCDE han establecido directrices:
• Los Principios de IA de la OCDE (2019) abogan por una IA que sea "robusta, segura, centrada en el ser humano, transparente, responsable y que promueva el bienestar inclusivo y sostenible".
• La Recomendación sobre la Ética de la Inteligencia Artificial de la UNESCO (2021) es el primer instrumento normativo global sobre el tema, que establece principios como "la proporcionalidad, la seguridad, la no discriminación, la sostenibilidad ambiental, la privacidad, la transparencia, la rendición de cuentas y la supervisión humana".
2.2 Privacidad y Riesgos en el Uso de la IA
La IA y los grandes modelos de lenguaje (LLMs) plantean nuevos riesgos, incluyendo la privacidad de los datos. El mal uso de la IA puede vulnerar derechos fundamentales como el derecho a la privacidad (vigilancia masiva, recolección de datos biométricos sin consentimiento) y el derecho a la no discriminación (generación o amplificación de sesgos algorítmicos).
La Ley de IA de la Unión Europea adopta un enfoque basado en el riesgo, evaluando los sistemas de manera diferenciada para garantizar que la regulación sea proporcional. Esta ley define varios niveles de riesgo:
1. Riesgo Inaceptable: Los sistemas con riesgos inaceptables están prohibidos. Esto incluye el uso de sistemas de IA que emplean técnicas subliminales o engañosas para distorsionar las decisiones informadas de las personas, o sistemas de identificación biométrica remota en tiempo real en espacios públicos (excepto bajo circunstancias excepcionales).
2. Alto Riesgo: Sistemas utilizados en sectores críticos como migración, asilo, control fronterizo, selección de currículums o infraestructura crítica. Estos sistemas deben superar evaluaciones de conformidad y cumplir con medidas estrictas de transparencia.
3. Riesgo Limitado (o de transparencia): Sistemas diseñados para interactuar directamente con personas, como chatbots. El requisito fundamental es que "los usuarios sean informados de manera clara y comprensible cuando están interactuando con un sistema de IA".
4. Riesgo Mínimo: Sistemas que no representan una amenaza significativa (ej. filtros de spam, sistemas de recomendación). Estos siguen sujetos a normativas generales como el Reglamento General de Protección de Datos (GDPR).
El Reglamento General de Protección de Datos (GDPR) de la UE es fundamental, ya que sus principios se refieren a la licitud, lealtad y transparencia, la limitación de la finalidad, la minimización de datos, y la responsabilidad proactiva, entre otros. La Ley de IA entra en vigor sin perjuicio de las obligaciones del GDPR, elevando la protección relativa al tratamiento de datos personales en algunos casos.
Para la implementación práctica de la IA responsable, Google Cloud, por ejemplo, utiliza "evaluaciones estrictas" realizadas por dos organismos de revisión distintos, y desarrolla herramientas como la IA explicable y Model Cards para proporcionar transparencia.
3. Descubrimiento Inicial del Proyecto (Contexto, Stakeholders)
Todo proyecto de software se inicia con el equipo intentando comprender el problema a resolver y "determinando qué resultados son importantes para los stakeholders". Este proceso comienza con la Concepción (Inception).
3.1 Inception y Elicitación de Requerimientos
En la etapa de concepción del proyecto, se establece un entendimiento básico del problema, de las personas que desean una solución y de la naturaleza de la solución deseada. También se definen las restricciones del proyecto y las principales características y funciones que deben estar presentes para cumplir los objetivos. En esta fase inicial es clave establecer la comunicación efectiva entre todos los stakeholders y el equipo de software.
La Elicitación (Elicitation) es el proceso de recopilación de requerimientos.
"Ciertamente parece bastante simple: pregunte al cliente, a los usuarios y a otros cuáles son los objetivos para el sistema o producto, qué se debe lograr, cómo encaja el sistema o producto en las necesidades del negocio y, finalmente, cómo se utilizará el sistema o producto en el día a día. Pero no es simple, es muy difícil" (Sommerville & Sawyer).
Las preguntas iniciales formuladas en la concepción deben ser "context free". Un ejemplo de preguntas para identificar a todos los interesados y el beneficio económico son:
• "¿Quién está detrás de la solicitud de este trabajo?".
• "¿Cuál será el beneficio económico de una solución exitosa?".
3.2 La Importancia de los Stakeholders
Un stakeholder (interesado) es "cualquiera que se beneficie de manera directa o indirecta del sistema que se está desarrollando" (Sommerville y Sawyer [Som97]). Un stakeholder es alguien que tiene una participación en el resultado exitoso del proyecto.
La lista de stakeholders puede incluir gerentes de negocios, gerentes de producto, personal de marketing, clientes internos y externos, usuarios finales, consultores, ingenieros de software y personal de soporte.
Rob Thomsett bromea: “un stakeholder es una persona que sostiene una estaca grande y afilada. . . . Si no cuidas a tus stakeholders, sabes dónde terminará la estaca”.
Debido a la existencia de muchos stakeholders diferentes, los requisitos del sistema se explorarán desde múltiples puntos de vista. Por ejemplo, el grupo de marketing está interesado en características fáciles de vender, mientras que los gerentes de negocios buscan un conjunto de características que puedan construirse "dentro del presupuesto y que estén listas para cumplir con las ventanas de mercado definidas".
Es fundamental reconocer que los requerimientos pueden entrar en conflicto. La colaboración es necesaria, pero no significa que los requerimientos sean "definidos por comité". En muchos casos, un "campeón del proyecto" fuerte (por ejemplo, un gerente de negocios) puede tomar la decisión final. Los conflictos pueden resolverse mediante esquemas de votación, como el uso de "Planning Poker", en el que los stakeholders gastan puntos de prioridad para indicar la importancia relativa de cada requisito.
3.3 El Descubrimiento en el Producto Digital (Discovery)
En el contexto del producto digital, el discovery (descubrimiento) es un proceso esencial que "comprende una serie de actividades que nos permiten entender el comportamiento de los usuarios, identificar sus problemas y necesidades, diseñar las soluciones más adecuadas y eficaces y ponerlas a prueba" (Sirven, 2024). Este proceso tiene el objetivo doble de entender el problema (Descubrimiento del Problema) y diseñar la solución (Descubrimiento de la Solución).
Una herramienta eficaz para estructurar las hipótesis al iniciar el discovery es el Lean Canvas. Este lienzo se centra en elementos clave orientados al producto o al mercado, como:
• Segmentos de usuarios: ¿Cuál es el público objetivo de tu producto?.
• El problema y las alternativas: ¿Cuáles son los 3 principales problemas que intentas resolver para tus potenciales primeros usuarios?.
• La propuesta de valor única: la razón por la que los clientes potenciales deberían convertirse en usuarios.
Es crucial evaluar la madurez del problema y el riesgo asociado al inicio. Si "El problema no está claramente identificado y el riesgo es alto", se debe llevar a cabo una fase de discovery avanzada. La inversión en discovery reduce el riesgo de fracaso, ya que "el desarrollo de una solución incorrecta puede ser mucho más costoso que invertir en le fase de discovery".

--------------------------------------------------------------------------------
Referencias Bibliográficas
Cárdenas, P. A. (2023). Design of a redundant and self-healing cloud architecture based on the Cloud Native Maturity Model of the Cloud Native Computing Foundation for a company in the Banking. (Tesis de maestría, Universidad Peruana de Ciencias Aplicadas).
Deng, S., Zhao, H., Huang, B., Zhang, C., Chen, F., Deng, Y., & Zomaya, A. (2023). Cloud-Native Computing: A Survey from the Perspective of Services. Distributed, Parallel, and Cluster Computing. https://doi.org/10.48550/arXiv.2306.14402.
Fagan, M. E. (1986). Advances in Software Inspections. IEEE Transactions on Software Engineering, 12(6)..
Gannon, D., Barga, R., & Sundaresan, N. (2017). Cloud-Native Applications. IEEE Cloud Computing, 4(5), 16-21..
Gartner. (n.d.). Nuevas tendencias en el sector del software empresarial..
Google Cloud. (n.d.). Una IA responsable..
Gomes, O. S., Braga e Silva, G., & Ferreira de Souza, É. (2022). Ethics in the Software Development Process: a Tertiary Literature Review..
Laszewski, T., Arora, K., & Farr, E. (2018). Cloud Native Architectures. Packt..
Lulichac Ramos, G., Pantoja Payajo, F., & Torres Villanueva, M. (2025). La IA Generativa en el Desarrollo de Software: Impacto en Diversas Industrias. Revista Innovación y Software, 6(1), 76-101..
Naur, P., & Randell, B. (1969). Ingeniería de software: Reporte de una conferencia patrocinada por el comité científico de la OTAN, Garmisch, Alemania, 7 a 11 de octubre de 1968..
Pitoura, E., et al. (2018). On Measuring Bias in Online Information. SIGMOD, 46(4)..
Schwaber, K., & Beedle, M. (2001). Agile Software Development with Scrum. Prentice Hall..
Sirven, F. (2024). ¿Qué es el discovery en producto digital y cómo implementarlo? Thiga Media..
Sommerville, I. (2011). Ingeniería de Software (9a ed.). Pearson Educación..
Sommerville, I., & Sawyer, P. (1997). Requirements Engineering: A Good Practice Guide. John Wiley & Sons..
Thoughtworks. (n.d.). Ingeniería de software con enfoque en IA..
Torres Jarrín, M. (2023). Artificial Intelligence and Foreign Affairs: Diplomacy, Geopolitics and Ethics in Latin America-Europe Relations..
Vakkuri, V., & Abrahamsson, P. (2018). The Key Concepts of Ethics of Artificial Intelligence. 2018 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)..
Velasco Pufleau, M. (2024). Inteligencia artificial y protección de datos personales: el caso del RGPD de la Unión Europea y sus implicaciones para América Latina y el Caribe. (En SELA, La gobernanza ética de la inteligencia artificial)..
Whittaker, M., Crawford, K., Dobbe, R., Fried, G., Kaziunas, E., Mathur, V., & Schwartz, O. (2018). Informe AI Now 2018. AI Now Institute..
